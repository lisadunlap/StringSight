# Test config for label() function (fixed-taxonomy analysis)
# This config enables label() mode by specifying a taxonomy

data_path: data/vlm_gym_ablation/FEEDBACK/ToyMaze3DEnv-v0__easy.json  # Update with your actual data path
output_dir: /home/lisabdunlap/StringSightNew/results/vlm_gym_ablation/FEEDBACK/ToyMaze3DEnv-v0__easy

# When taxonomy is specified, the script automatically uses label() mode instead of explain()
# Option 1: Inline taxonomy (define taxonomy directly in YAML)
taxonomy:
  "Action looping and miscalibration": |
    The model keeps repeating the same or nearly identical action without making progress. Look for consecutive turns with the same command or sequence of commands, movements by the same amount, or the same tool being used even when it is ineffective.
  
  "State mismanagement": |
    The model forgets or ignores what it already learned in earlier steps. It may revisit old states, contradict past reasoning, or repeat mistakes it was corrected for (e.g. being told it hit a wall and then continuing to move forward in the same direction). Do not include if this is simply action looping, where the model is repeating the same action without making progress; this is specifically when the model is ignoring feedback or not adjusting its behavior based on its previous actions, but is still issuing different commands.
  
  "Inappropriate termination": |
    The model stops too early. Early means terminating before the maximum number of steps is reached.
  
  "Failure to use visual or spatial information": |
    The model ignores visible or spatial cues. This applies to traces where either an image or ascii art is provided and the model does not react to changes in the scene. For example, if the object leaves the frame but the model continues to move towards it. Look for actions that contradict whatâ€™s visually or spatially clear. Do not include if the model is simply action looping, where the model is repeating the same action without making progress; this is specifically when the model is not utilizing the visual information when it is available. If the trace does not provide visual information, do not include this label.

  "Lazyness or giving up on the task": |
    The model explicitly gives up on the task. Look for actions that indicate the model is giving up, such as "stop" or "done" commands along with verbalization that the model is giving up because the problem is too difficult. 

# Option 2: Reference external JSON file (uncomment to use)
# taxonomy: path/to/taxonomy.json

# Label-specific parameters
extraction_model: gpt-4.1  # Model for labeling (used as model_name in label())
label_temperature: 0.0      # Temperature for label() LLM (default: 0.0)
label_top_p: 1.0            # Top-p for label() LLM (default: 1.0)
label_max_tokens: 2048      # Max tokens for label() LLM (default: 2048)

# Common parameters
max_workers: 8
sample_size: null  # Set to a number to sample, or null to use full dataset
disable_wandb: false
quiet: false

# Column mapping (if your data uses different column names)
prompt_column: prompt
model_column: model
model_response_column: model_response
question_id_column: question_id

# Score columns (if your data has score metrics)
score_columns:
  - accuracy
  - harmfulness

# Metrics configuration
metrics_kwargs:
  compute_bootstrap: true
  bootstrap_samples: 100

# Caching (optional)
extraction_cache_dir: .cache/stringsight/extraction
metrics_cache_dir: .cache/stringsight/metrics

